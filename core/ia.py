# Migraci贸n de la clase principal y funciones desde core_ia.py
import torch
from PIL import Image
from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration, BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM
import json
import os
import random
import pyttsx3
from gtts import gTTS
import pygame
from io import BytesIO
import speech_recognition as sr
from datetime import datetime
import ollama
from brain_conceptual import BrainConceptual
from brain_mechanical import BrainMechanical
from brain_medical import BrainMedical
from database_handler import DatabaseHandler
from personality_trainer import PersonalityTrainer
# RVCVoiceCloner se importa bajo demanda en enable_voice_cloning()
from episodic_memory import EpisodicMemory
from personality_config import PersonalityConfig
from response_postprocessor import ResponsePostprocessor
from strategic_reasoning import StrategicReasoning

# Importar backend de llama.cpp (con manejo de errores)
try:
	from optimizacion_llama import LlamaCppBackend
	LLAMA_CPP_AVAILABLE = True
except Exception as e:
	LLAMA_CPP_AVAILABLE = False
	print(f"锔 llama.cpp no disponible: {e}")

# Memoria compartida (ahora manejada por DatabaseHandler)
MEMORY_FILE = "tars_memory.json"

class TarsVision:
	def __init__(self):
		self.device = "cuda" if torch.cuda.is_available() else "cpu"
		print(f" TARS: Iniciando en {self.device}...")
		print(" Cargando solo lo esencial (modo optimizado)")
		# ...existing code...

	# ...resto de m茅todos y l贸gica migrados...

# Punto de entrada para ejecutar la IA modular
def main():
	# Ejemplo de uso
	tars = TarsVision()
	print("TARS IA modular iniciada.")
	# ...existing code...
"""
M贸dulo: ia.py
L贸gica principal de IA, generaci贸n de respuestas, integraci贸n de modelos.
Extra铆do de core_ia.py
"""

# Aqu铆 ir谩 la clase TarsVision y funciones de generaci贸n de respuesta
