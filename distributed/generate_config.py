#!/usr/bin/env python3
"""
Dynamic Configuration Generator
Genera configuración optimizada según el hardware detectado
"""

import json
import os
from typing import Dict, Any
from distributed.smart_setup import HardwareDetector, OptimizationEngine

class ConfigurationGenerator:
    """Generate optimized .env files and configuration"""
    
    @staticmethod
    def generate_env_file(role: str, 
                         hardware_tier: str,
                         coordinator_host: str = None,
                         port: int = None) -> str:
        """Generate .env file content"""
        
        # Detect hardware for resource limits
        detector = HardwareDetector()
        hardware = detector.detect_hardware()
        optimization = OptimizationEngine.generate_profile(hardware)
        
        base_config = {
            "coordinator": {
                "TARS_PC_NAME": "PC1",
                "TARS_HOST": "0.0.0.0",
                "TARS_PORT": 8000,
                "TARS_IS_COORDINATOR": "true",
                "TARS_REMOTE_HOST": "None",
                "TARS_REMOTE_PORT": "None",
                "CUDA_VISIBLE_DEVICES": "0",
                "CUDA_LAUNCH_BLOCKING": "false",
                "TORCH_CUDA_MEMORY_FRACTION": 0.85,
                "NUM_WORKERS": optimization.num_workers,
                "BATCH_SIZE": optimization.batch_size,
                "MAX_BATCH_SIZE": optimization.max_batch_size,
                "INFERENCE_FRAMEWORK": optimization.inference_framework,
                "QUANTIZATION": optimization.quantization,
                "LOG_LEVEL": "INFO",
            },
            "worker": {
                "TARS_PC_NAME": "PC2",
                "TARS_HOST": "0.0.0.0",
                "TARS_PORT": 8001,
                "TARS_IS_COORDINATOR": "false",
                "TARS_REMOTE_HOST": coordinator_host or "localhost",
                "TARS_REMOTE_PORT": 8000,
                "CUDA_VISIBLE_DEVICES": "0",
                "CUDA_LAUNCH_BLOCKING": "true",
                "TORCH_CUDA_MEMORY_FRACTION": 0.90,
                "NUM_WORKERS": max(2, optimization.num_workers // 2),
                "BATCH_SIZE": max(2, optimization.batch_size // 2),
                "MAX_BATCH_SIZE": max(4, optimization.max_batch_size // 2),
                "INFERENCE_FRAMEWORK": optimization.inference_framework,
                "QUANTIZATION": optimization.quantization,
                "LOG_LEVEL": "INFO",
            },
            "standalone": {
                "TARS_PC_NAME": "STANDALONE",
                "TARS_HOST": "0.0.0.0",
                "TARS_PORT": 8000,
                "TARS_IS_COORDINATOR": "true",
                "TARS_REMOTE_HOST": "None",
                "TARS_REMOTE_PORT": "None",
                "CUDA_VISIBLE_DEVICES": "0",
                "CUDA_LAUNCH_BLOCKING": "false",
                "TORCH_CUDA_MEMORY_FRACTION": 0.85,
                "NUM_WORKERS": optimization.num_workers,
                "BATCH_SIZE": optimization.batch_size,
                "MAX_BATCH_SIZE": optimization.max_batch_size,
                "INFERENCE_FRAMEWORK": optimization.inference_framework,
                "QUANTIZATION": optimization.quantization,
                "LOG_LEVEL": "INFO",
            }
        }
        
        config = base_config.get(role, base_config["standalone"])
        
        # Build .env file
        env_lines = [
            "# TARS Distributed System Configuration",
            "# Auto-generated by smart_setup.py",
            "# DO NOT EDIT MANUALLY\n",
        ]
        
        for key, value in config.items():
            if isinstance(value, bool):
                value = "true" if value else "false"
            env_lines.append(f"{key}={value}")
        
        return "\n".join(env_lines) + "\n"
    
    @staticmethod
    def generate_docker_compose(components: Dict[str, bool]) -> str:
        """Generate docker-compose.yml for optional components"""
        
        services = {
            "backend": {
                "build": ".",
                "ports": ["8000:8000", "8001:8001"],
                "environment": ["CUDA_VISIBLE_DEVICES=0"],
                "volumes": ["./models:/app/models"],
                "restart": "always",
            }
        }
        
        if components.get("postgresql"):
            services["postgres"] = {
                "image": "postgres:15",
                "environment": ["POSTGRES_PASSWORD=tars_password"],
                "ports": ["5432:5432"],
                "volumes": ["postgres_data:/var/lib/postgresql/data"],
                "restart": "unless-stopped",
            }
        
        if components.get("redis"):
            services["redis"] = {
                "image": "redis:7-alpine",
                "ports": ["6379:6379"],
                "restart": "unless-stopped",
            }
        
        if components.get("monitoring"):
            services["prometheus"] = {
                "image": "prom/prometheus",
                "ports": ["9090:9090"],
                "volumes": ["./prometheus.yml:/etc/prometheus/prometheus.yml"],
                "restart": "unless-stopped",
            }
            services["grafana"] = {
                "image": "grafana/grafana",
                "ports": ["3001:3000"],
                "environment": ["GF_SECURITY_ADMIN_PASSWORD=admin"],
                "volumes": ["grafana_data:/var/lib/grafana"],
                "restart": "unless-stopped",
            }
        
        docker_compose = {
            "version": "3.8",
            "services": services,
            "volumes": {}
        }
        
        if components.get("postgresql"):
            docker_compose["volumes"]["postgres_data"] = {}
        
        if components.get("monitoring"):
            docker_compose["volumes"]["grafana_data"] = {}
        
        return yaml_dumps(docker_compose)


def yaml_dumps(data: Dict) -> str:
    """Simple YAML-like output"""
    lines = []
    
    def format_dict(d: Dict, indent: int = 0):
        for key, value in d.items():
            spaces = "  " * indent
            if isinstance(value, dict):
                lines.append(f"{spaces}{key}:")
                format_dict(value, indent + 1)
            elif isinstance(value, list):
                if len(value) == 0:
                    lines.append(f"{spaces}{key}: []")
                elif isinstance(value[0], str):
                    lines.append(f"{spaces}{key}:")
                    for item in value:
                        lines.append(f"{spaces}  - {item}")
                else:
                    lines.append(f"{spaces}{key}:")
                    for item in value:
                        format_dict({"": item}, indent + 1)
            else:
                lines.append(f"{spaces}{key}: {value}")
    
    format_dict(data)
    return "\n".join(lines) + "\n"


def generate_all_configs(config: Dict[str, Any]):
    """Generate all configuration files"""
    
    role = config["pc_role"]
    coordinator_host = config.get("coordinator_host")
    components = config.get("additional_components", {})
    
    # Generate .env file
    env_content = ConfigurationGenerator.generate_env_file(
        role=role,
        hardware_tier=config["hardware"]["gpu_tier"],
        coordinator_host=coordinator_host
    )
    
    env_filename = f".env.{role}"
    with open(env_filename, "w") as f:
        f.write(env_content)
    
    print(f"✅ Generated {env_filename}")
    
    # Generate docker-compose if needed
    if config.get("deployment_type") == "docker":
        docker_content = ConfigurationGenerator.generate_docker_compose(components)
        with open("docker-compose.generated.yml", "w") as f:
            f.write(docker_content)
        print("✅ Generated docker-compose.generated.yml")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        config_file = sys.argv[1]
        with open(config_file) as f:
            config = json.load(f)
        generate_all_configs(config)
    else:
        print("Usage: python3 generate_config.py <config.json>")
